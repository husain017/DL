{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Test1_J056.ipynb",
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "id": "Hvmjt7CTxSbM",
        "colab_type": "code",
        "outputId": "32fb0777-b57d-41ec-8d75-95aecafe9061",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 81
        }
      },
      "source": [
        "import keras\n",
        "from keras import models\n",
        "from keras.layers import Dense, Dropout\n",
        "from keras.utils import to_categorical\n",
        "from keras.datasets import mnist\n",
        "from keras.utils.vis_utils import model_to_dot\n",
        "from IPython.display import SVG"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Using TensorFlow backend.\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "<p style=\"color: red;\">\n",
              "The default version of TensorFlow in Colab will soon switch to TensorFlow 2.x.<br>\n",
              "We recommend you <a href=\"https://www.tensorflow.org/guide/migrate\" target=\"_blank\">upgrade</a> now \n",
              "or ensure your notebook will continue to use TensorFlow 1.x via the <code>%tensorflow_version 1.x</code> magic:\n",
              "<a href=\"https://colab.research.google.com/notebooks/tensorflow_version.ipynb\" target=\"_blank\">more info</a>.</p>\n"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ngxSssujzPt4",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "NUM_ROWS = 28\n",
        "NUM_COLS = 28\n",
        "NUM_CLASSES = 10\n",
        "BATCH_SIZE = 128\n",
        "EPOCHS = 10"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "a8Ps_u-pzRUQ",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "(X_train, y_train), (X_test, y_test) = mnist.load_data()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "P3_53Y0CzVoj",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "X_train = X_train.reshape((X_train.shape[0], NUM_ROWS * NUM_COLS))\n",
        "X_train = X_train.astype('float32') / 255\n",
        "X_test = X_test.reshape((X_test.shape[0], NUM_ROWS * NUM_COLS))\n",
        "X_test = X_test.astype('float32') / 255"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5xzKf57uzYf5",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "y_train = to_categorical(y_train, NUM_CLASSES)\n",
        "y_test = to_categorical(y_test, NUM_CLASSES)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "H924iEeJzdWm",
        "colab_type": "code",
        "outputId": "26c0112c-59d7-41e0-9a6e-21dab997c307",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 141
        }
      },
      "source": [
        "model = models.Sequential()\n",
        "model.add(Dense(512, activation='relu', input_shape=(NUM_ROWS * NUM_COLS,)))\n",
        "model.add(Dense(256, activation='relu'))\n",
        "model.add(Dense(10, activation='softmax'))"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:66: The name tf.get_default_graph is deprecated. Please use tf.compat.v1.get_default_graph instead.\n",
            "\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:541: The name tf.placeholder is deprecated. Please use tf.compat.v1.placeholder instead.\n",
            "\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:4432: The name tf.random_uniform is deprecated. Please use tf.random.uniform instead.\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "IvxvB3XJzfG0",
        "colab_type": "code",
        "outputId": "6dfadd78-1ffe-4b8f-d02a-068a2622f747",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 107
        }
      },
      "source": [
        "model.compile(optimizer='rmsprop',\n",
        "              loss='categorical_crossentropy',\n",
        "              metrics=['accuracy'])"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/optimizers.py:793: The name tf.train.Optimizer is deprecated. Please use tf.compat.v1.train.Optimizer instead.\n",
            "\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:3576: The name tf.log is deprecated. Please use tf.math.log instead.\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "HL83shaizk2h",
        "colab_type": "code",
        "outputId": "4207468c-4423-4427-ba26-d1a5c8520beb",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 765
        }
      },
      "source": [
        "model.fit(X_train, y_train,\n",
        "          batch_size=BATCH_SIZE,\n",
        "          epochs=EPOCHS,\n",
        "          verbose=1,\n",
        "          validation_data=(X_test, y_test))\n",
        "\n",
        "score = model.evaluate(X_test, y_test, verbose=0)\n",
        "print('Test loss:', score[0])\n",
        "print('Test accuracy:', score[1])"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/tensorflow_core/python/ops/math_grad.py:1424: where (from tensorflow.python.ops.array_ops) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Use tf.where in 2.0, which has the same broadcast rule as np.where\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:1033: The name tf.assign_add is deprecated. Please use tf.compat.v1.assign_add instead.\n",
            "\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:1020: The name tf.assign is deprecated. Please use tf.compat.v1.assign instead.\n",
            "\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:3005: The name tf.Session is deprecated. Please use tf.compat.v1.Session instead.\n",
            "\n",
            "Train on 60000 samples, validate on 10000 samples\n",
            "Epoch 1/10\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:190: The name tf.get_default_session is deprecated. Please use tf.compat.v1.get_default_session instead.\n",
            "\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:197: The name tf.ConfigProto is deprecated. Please use tf.compat.v1.ConfigProto instead.\n",
            "\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:207: The name tf.global_variables is deprecated. Please use tf.compat.v1.global_variables instead.\n",
            "\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:216: The name tf.is_variable_initialized is deprecated. Please use tf.compat.v1.is_variable_initialized instead.\n",
            "\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:223: The name tf.variables_initializer is deprecated. Please use tf.compat.v1.variables_initializer instead.\n",
            "\n",
            "60000/60000 [==============================] - 5s 83us/step - loss: 0.2264 - acc: 0.9309 - val_loss: 0.1085 - val_acc: 0.9658\n",
            "Epoch 2/10\n",
            "60000/60000 [==============================] - 5s 81us/step - loss: 0.0838 - acc: 0.9742 - val_loss: 0.0718 - val_acc: 0.9792\n",
            "Epoch 3/10\n",
            "60000/60000 [==============================] - 5s 81us/step - loss: 0.0553 - acc: 0.9823 - val_loss: 0.0734 - val_acc: 0.9778\n",
            "Epoch 4/10\n",
            "60000/60000 [==============================] - 5s 80us/step - loss: 0.0402 - acc: 0.9877 - val_loss: 0.0821 - val_acc: 0.9777\n",
            "Epoch 5/10\n",
            "60000/60000 [==============================] - 5s 83us/step - loss: 0.0290 - acc: 0.9912 - val_loss: 0.0880 - val_acc: 0.9792\n",
            "Epoch 6/10\n",
            "60000/60000 [==============================] - 5s 83us/step - loss: 0.0225 - acc: 0.9931 - val_loss: 0.0911 - val_acc: 0.9771\n",
            "Epoch 7/10\n",
            "60000/60000 [==============================] - 5s 82us/step - loss: 0.0186 - acc: 0.9941 - val_loss: 0.0757 - val_acc: 0.9819\n",
            "Epoch 8/10\n",
            "60000/60000 [==============================] - 5s 82us/step - loss: 0.0152 - acc: 0.9954 - val_loss: 0.0942 - val_acc: 0.9809\n",
            "Epoch 9/10\n",
            "60000/60000 [==============================] - 5s 81us/step - loss: 0.0124 - acc: 0.9961 - val_loss: 0.0925 - val_acc: 0.9818\n",
            "Epoch 10/10\n",
            "60000/60000 [==============================] - 5s 80us/step - loss: 0.0102 - acc: 0.9965 - val_loss: 0.1012 - val_acc: 0.9815\n",
            "Test loss: 0.10121400504868534\n",
            "Test accuracy: 0.9815\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "j4FINhUV2Udb",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from keras import optimizers\n",
        "sgd=keras.optimizers.SGD(lr=0.01, momentum=0.0, nesterov=False)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "tlSr--_B2ZMI",
        "colab_type": "code",
        "outputId": "bd61b1ef-1f88-46ba-84fa-d43ac59e6f3a",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 416
        }
      },
      "source": [
        "# Compile model using above optimizer\n",
        "model.compile(optimizer=sgd,\n",
        "              loss='categorical_crossentropy',\n",
        "              metrics=['accuracy'])\n",
        "\n",
        "# Train model\n",
        "model.fit(X_train, y_train,\n",
        "          batch_size=BATCH_SIZE,\n",
        "          epochs=EPOCHS,\n",
        "          verbose=1,\n",
        "          validation_data=(X_test, y_test))\n",
        "\n",
        "score = model.evaluate(X_test, y_test, verbose=0)\n",
        "print('Test loss:', score[0])\n",
        "print('Test accuracy:', score[1])"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Train on 60000 samples, validate on 10000 samples\n",
            "Epoch 1/10\n",
            "60000/60000 [==============================] - 4s 70us/step - loss: 0.0034 - acc: 0.9990 - val_loss: 0.0928 - val_acc: 0.9830\n",
            "Epoch 2/10\n",
            "60000/60000 [==============================] - 4s 69us/step - loss: 0.0022 - acc: 0.9995 - val_loss: 0.0913 - val_acc: 0.9833\n",
            "Epoch 3/10\n",
            "60000/60000 [==============================] - 4s 71us/step - loss: 0.0018 - acc: 0.9997 - val_loss: 0.0904 - val_acc: 0.9837\n",
            "Epoch 4/10\n",
            "60000/60000 [==============================] - 4s 68us/step - loss: 0.0015 - acc: 0.9998 - val_loss: 0.0899 - val_acc: 0.9836\n",
            "Epoch 5/10\n",
            "60000/60000 [==============================] - 4s 68us/step - loss: 0.0014 - acc: 0.9998 - val_loss: 0.0895 - val_acc: 0.9838\n",
            "Epoch 6/10\n",
            "60000/60000 [==============================] - 4s 68us/step - loss: 0.0013 - acc: 0.9999 - val_loss: 0.0892 - val_acc: 0.9836\n",
            "Epoch 7/10\n",
            "60000/60000 [==============================] - 4s 68us/step - loss: 0.0012 - acc: 0.9999 - val_loss: 0.0889 - val_acc: 0.9836\n",
            "Epoch 8/10\n",
            "60000/60000 [==============================] - 4s 68us/step - loss: 0.0011 - acc: 0.9999 - val_loss: 0.0886 - val_acc: 0.9836\n",
            "Epoch 9/10\n",
            "60000/60000 [==============================] - 4s 67us/step - loss: 0.0010 - acc: 0.9999 - val_loss: 0.0884 - val_acc: 0.9836\n",
            "Epoch 10/10\n",
            "60000/60000 [==============================] - 4s 68us/step - loss: 9.9383e-04 - acc: 0.9999 - val_loss: 0.0882 - val_acc: 0.9836\n",
            "Test loss: 0.08824600390014066\n",
            "Test accuracy: 0.9836\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "NPYhv4wU2bva",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from keras import optimizers\n",
        "rms=keras.optimizers.RMSprop(lr=0.001, rho=0.9)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "pXA1ryEc2fm-",
        "colab_type": "code",
        "outputId": "8b9a3c35-ef9a-4eae-b7c9-0dfc7fefe941",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 416
        }
      },
      "source": [
        "# Compile model using above optimizer\n",
        "model.compile(optimizer=rms,\n",
        "              loss='categorical_crossentropy',\n",
        "              metrics=['accuracy'])\n",
        "\n",
        "# Train model\n",
        "model.fit(X_train, y_train,\n",
        "          batch_size=BATCH_SIZE,\n",
        "          epochs=EPOCHS,\n",
        "          verbose=1,\n",
        "          validation_data=(X_test, y_test))\n",
        "\n",
        "score = model.evaluate(X_test, y_test, verbose=0)\n",
        "print('Test loss:', score[0])\n",
        "print('Test accuracy:', score[1])"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Train on 60000 samples, validate on 10000 samples\n",
            "Epoch 1/10\n",
            "60000/60000 [==============================] - 5s 86us/step - loss: 0.0108 - acc: 0.9970 - val_loss: 0.0865 - val_acc: 0.9836\n",
            "Epoch 2/10\n",
            "60000/60000 [==============================] - 5s 82us/step - loss: 0.0092 - acc: 0.9974 - val_loss: 0.1018 - val_acc: 0.9830\n",
            "Epoch 3/10\n",
            "60000/60000 [==============================] - 5s 82us/step - loss: 0.0079 - acc: 0.9978 - val_loss: 0.1150 - val_acc: 0.9818\n",
            "Epoch 4/10\n",
            "60000/60000 [==============================] - 5s 81us/step - loss: 0.0070 - acc: 0.9979 - val_loss: 0.0974 - val_acc: 0.9851\n",
            "Epoch 5/10\n",
            "60000/60000 [==============================] - 5s 82us/step - loss: 0.0064 - acc: 0.9982 - val_loss: 0.1179 - val_acc: 0.9827\n",
            "Epoch 6/10\n",
            "60000/60000 [==============================] - 5s 81us/step - loss: 0.0052 - acc: 0.9985 - val_loss: 0.1182 - val_acc: 0.9837\n",
            "Epoch 7/10\n",
            "60000/60000 [==============================] - 5s 82us/step - loss: 0.0049 - acc: 0.9986 - val_loss: 0.1110 - val_acc: 0.9839\n",
            "Epoch 8/10\n",
            "60000/60000 [==============================] - 5s 82us/step - loss: 0.0053 - acc: 0.9987 - val_loss: 0.1236 - val_acc: 0.9825\n",
            "Epoch 9/10\n",
            "60000/60000 [==============================] - 5s 82us/step - loss: 0.0051 - acc: 0.9986 - val_loss: 0.1338 - val_acc: 0.9831\n",
            "Epoch 10/10\n",
            "60000/60000 [==============================] - 5s 82us/step - loss: 0.0045 - acc: 0.9987 - val_loss: 0.1322 - val_acc: 0.9830\n",
            "Test loss: 0.132220922436216\n",
            "Test accuracy: 0.983\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4-r3fjto2i44",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from keras import optimizers\n",
        "ada=keras.optimizers.Adagrad(lr=0.01)\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "eQYz6kMK2mJT",
        "colab_type": "code",
        "outputId": "5d8fd1c0-5b2a-4399-9fc7-9fc36109bc06",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 416
        }
      },
      "source": [
        "# Compile model using above optimizer\n",
        "model.compile(optimizer=ada,\n",
        "              loss='categorical_crossentropy',\n",
        "              metrics=['accuracy'])\n",
        "\n",
        "# Train model\n",
        "model.fit(X_train, y_train,\n",
        "          batch_size=BATCH_SIZE,\n",
        "          epochs=EPOCHS,\n",
        "          verbose=1,\n",
        "          validation_data=(X_test, y_test))\n",
        "\n",
        "score = model.evaluate(X_test, y_test, verbose=0)\n",
        "print('Test loss:', score[0])\n",
        "print('Test accuracy:', score[1])"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Train on 60000 samples, validate on 10000 samples\n",
            "Epoch 1/10\n",
            "60000/60000 [==============================] - 5s 79us/step - loss: 0.0324 - acc: 0.9954 - val_loss: 0.1212 - val_acc: 0.9844\n",
            "Epoch 2/10\n",
            "60000/60000 [==============================] - 5s 77us/step - loss: 4.9875e-04 - acc: 0.9999 - val_loss: 0.1175 - val_acc: 0.9857\n",
            "Epoch 3/10\n",
            "60000/60000 [==============================] - 5s 78us/step - loss: 3.0716e-04 - acc: 1.0000 - val_loss: 0.1167 - val_acc: 0.9856\n",
            "Epoch 4/10\n",
            "60000/60000 [==============================] - 5s 77us/step - loss: 2.9204e-04 - acc: 1.0000 - val_loss: 0.1164 - val_acc: 0.9858\n",
            "Epoch 5/10\n",
            "60000/60000 [==============================] - 5s 76us/step - loss: 2.8844e-04 - acc: 1.0000 - val_loss: 0.1162 - val_acc: 0.9858\n",
            "Epoch 6/10\n",
            "60000/60000 [==============================] - 5s 80us/step - loss: 2.8620e-04 - acc: 1.0000 - val_loss: 0.1161 - val_acc: 0.9859\n",
            "Epoch 7/10\n",
            "60000/60000 [==============================] - 5s 76us/step - loss: 2.8454e-04 - acc: 1.0000 - val_loss: 0.1160 - val_acc: 0.9858\n",
            "Epoch 8/10\n",
            "60000/60000 [==============================] - 5s 77us/step - loss: 2.8325e-04 - acc: 1.0000 - val_loss: 0.1159 - val_acc: 0.9858\n",
            "Epoch 9/10\n",
            "60000/60000 [==============================] - 5s 77us/step - loss: 2.8222e-04 - acc: 1.0000 - val_loss: 0.1159 - val_acc: 0.9858\n",
            "Epoch 10/10\n",
            "60000/60000 [==============================] - 5s 76us/step - loss: 2.8135e-04 - acc: 1.0000 - val_loss: 0.1158 - val_acc: 0.9859\n",
            "Test loss: 0.11581552060002513\n",
            "Test accuracy: 0.9859\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "v1nsWOSI2n9B",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from keras import optimizers\n",
        "adelta=keras.optimizers.Adadelta(lr=1.0, rho=0.95)\n",
        "\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "omaJvTMJ2q3x",
        "colab_type": "code",
        "outputId": "2e49b981-65df-4b96-a2fd-cae5694965d3",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 416
        }
      },
      "source": [
        "# Compile model using above optimizer\n",
        "model.compile(optimizer=adelta,\n",
        "              loss='categorical_crossentropy',\n",
        "              metrics=['accuracy'])\n",
        "\n",
        "# Train model\n",
        "model.fit(X_train, y_train,\n",
        "          batch_size=BATCH_SIZE,\n",
        "          epochs=EPOCHS,\n",
        "          verbose=1,\n",
        "          validation_data=(X_test, y_test))\n",
        "\n",
        "score = model.evaluate(X_test, y_test, verbose=0)\n",
        "print('Test loss:', score[0])\n",
        "print('Test accuracy:', score[1])"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Train on 60000 samples, validate on 10000 samples\n",
            "Epoch 1/10\n",
            "60000/60000 [==============================] - 6s 104us/step - loss: 2.8064e-04 - acc: 1.0000 - val_loss: 0.1157 - val_acc: 0.9861\n",
            "Epoch 2/10\n",
            "60000/60000 [==============================] - 6s 98us/step - loss: 2.7867e-04 - acc: 1.0000 - val_loss: 0.1156 - val_acc: 0.9861\n",
            "Epoch 3/10\n",
            "60000/60000 [==============================] - 6s 99us/step - loss: 2.7736e-04 - acc: 1.0000 - val_loss: 0.1155 - val_acc: 0.9861\n",
            "Epoch 4/10\n",
            "60000/60000 [==============================] - 6s 100us/step - loss: 2.7641e-04 - acc: 1.0000 - val_loss: 0.1155 - val_acc: 0.9861\n",
            "Epoch 5/10\n",
            "60000/60000 [==============================] - 6s 100us/step - loss: 2.7569e-04 - acc: 1.0000 - val_loss: 0.1155 - val_acc: 0.9862\n",
            "Epoch 6/10\n",
            "60000/60000 [==============================] - 6s 100us/step - loss: 2.7512e-04 - acc: 1.0000 - val_loss: 0.1154 - val_acc: 0.9862\n",
            "Epoch 7/10\n",
            "60000/60000 [==============================] - 6s 100us/step - loss: 2.7467e-04 - acc: 1.0000 - val_loss: 0.1155 - val_acc: 0.9864\n",
            "Epoch 8/10\n",
            "60000/60000 [==============================] - 6s 100us/step - loss: 2.7428e-04 - acc: 1.0000 - val_loss: 0.1155 - val_acc: 0.9864\n",
            "Epoch 9/10\n",
            "60000/60000 [==============================] - 6s 100us/step - loss: 2.7395e-04 - acc: 1.0000 - val_loss: 0.1155 - val_acc: 0.9865\n",
            "Epoch 10/10\n",
            "60000/60000 [==============================] - 6s 99us/step - loss: 2.7366e-04 - acc: 1.0000 - val_loss: 0.1155 - val_acc: 0.9864\n",
            "Test loss: 0.11553933457914486\n",
            "Test accuracy: 0.9864\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "m6mV2tEJ2tOh",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from keras import optimizers\n",
        "adam=keras.optimizers.Adam(lr=0.001, beta_1=0.9, beta_2=0.999, amsgrad=False)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "uw6k9oX72wy_",
        "colab_type": "code",
        "outputId": "53239d7f-4e87-43c1-b258-6ab08d74fb5f",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 416
        }
      },
      "source": [
        "# Compile model using above optimizer\n",
        "model.compile(optimizer=adam,\n",
        "              loss='categorical_crossentropy',\n",
        "              metrics=['accuracy'])\n",
        "\n",
        "# Train model\n",
        "model.fit(X_train, y_train,\n",
        "          batch_size=BATCH_SIZE,\n",
        "          epochs=EPOCHS,\n",
        "          verbose=1,\n",
        "          validation_data=(X_test, y_test))\n",
        "\n",
        "score = model.evaluate(X_test, y_test, verbose=0)\n",
        "print('Test loss:', score[0])\n",
        "print('Test accuracy:', score[1])"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Train on 60000 samples, validate on 10000 samples\n",
            "Epoch 1/10\n",
            "60000/60000 [==============================] - 6s 95us/step - loss: 0.0223 - acc: 0.9951 - val_loss: 0.1632 - val_acc: 0.9781\n",
            "Epoch 2/10\n",
            "60000/60000 [==============================] - 5s 88us/step - loss: 0.0101 - acc: 0.9970 - val_loss: 0.1203 - val_acc: 0.9820\n",
            "Epoch 3/10\n",
            "60000/60000 [==============================] - 5s 88us/step - loss: 0.0114 - acc: 0.9970 - val_loss: 0.1204 - val_acc: 0.9815\n",
            "Epoch 4/10\n",
            "60000/60000 [==============================] - 5s 88us/step - loss: 0.0130 - acc: 0.9964 - val_loss: 0.1274 - val_acc: 0.9795\n",
            "Epoch 5/10\n",
            "60000/60000 [==============================] - 5s 89us/step - loss: 0.0189 - acc: 0.9952 - val_loss: 0.1382 - val_acc: 0.9773\n",
            "Epoch 6/10\n",
            "60000/60000 [==============================] - 5s 89us/step - loss: 0.0073 - acc: 0.9976 - val_loss: 0.1095 - val_acc: 0.9823\n",
            "Epoch 7/10\n",
            "60000/60000 [==============================] - 5s 89us/step - loss: 0.0086 - acc: 0.9976 - val_loss: 0.1143 - val_acc: 0.9836\n",
            "Epoch 8/10\n",
            "60000/60000 [==============================] - 5s 90us/step - loss: 0.0065 - acc: 0.9983 - val_loss: 0.1187 - val_acc: 0.9825\n",
            "Epoch 9/10\n",
            "60000/60000 [==============================] - 5s 90us/step - loss: 0.0083 - acc: 0.9977 - val_loss: 0.1517 - val_acc: 0.9771\n",
            "Epoch 10/10\n",
            "60000/60000 [==============================] - 5s 89us/step - loss: 0.0143 - acc: 0.9957 - val_loss: 0.1067 - val_acc: 0.9820\n",
            "Test loss: 0.1066820100943532\n",
            "Test accuracy: 0.982\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "HaTBiU-x2yp8",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from keras import optimizers\n",
        "adamax=keras.optimizers.Adamax(lr=0.002, beta_1=0.9, beta_2=0.999)\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "HoKzXIbP21CC",
        "colab_type": "code",
        "outputId": "75f49e71-f7db-4fd0-85e8-7e1fb0d65b87",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 416
        }
      },
      "source": [
        "# Compile model using above optimizer\n",
        "model.compile(optimizer=adamax,\n",
        "              loss='categorical_crossentropy',\n",
        "              metrics=['accuracy'])\n",
        "\n",
        "# Train model\n",
        "model.fit(X_train, y_train,\n",
        "          batch_size=BATCH_SIZE,\n",
        "          epochs=EPOCHS,\n",
        "          verbose=1,\n",
        "          validation_data=(X_test, y_test))\n",
        "\n",
        "score = model.evaluate(X_test, y_test, verbose=0)\n",
        "print('Test loss:', score[0])\n",
        "print('Test accuracy:', score[1])"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Train on 60000 samples, validate on 10000 samples\n",
            "Epoch 1/10\n",
            "60000/60000 [==============================] - 5s 88us/step - loss: 0.0023 - acc: 0.9993 - val_loss: 0.0978 - val_acc: 0.9849\n",
            "Epoch 2/10\n",
            "60000/60000 [==============================] - 5s 83us/step - loss: 3.4813e-04 - acc: 1.0000 - val_loss: 0.0963 - val_acc: 0.9852\n",
            "Epoch 3/10\n",
            "60000/60000 [==============================] - 5s 82us/step - loss: 2.9622e-04 - acc: 1.0000 - val_loss: 0.0962 - val_acc: 0.9847\n",
            "Epoch 4/10\n",
            "60000/60000 [==============================] - 5s 81us/step - loss: 2.8676e-04 - acc: 1.0000 - val_loss: 0.0969 - val_acc: 0.9848\n",
            "Epoch 5/10\n",
            "60000/60000 [==============================] - 5s 81us/step - loss: 2.8154e-04 - acc: 1.0000 - val_loss: 0.0979 - val_acc: 0.9853\n",
            "Epoch 6/10\n",
            "60000/60000 [==============================] - 5s 88us/step - loss: 2.7765e-04 - acc: 1.0000 - val_loss: 0.0989 - val_acc: 0.9855\n",
            "Epoch 7/10\n",
            "60000/60000 [==============================] - 5s 86us/step - loss: 2.7477e-04 - acc: 1.0000 - val_loss: 0.1002 - val_acc: 0.9856\n",
            "Epoch 8/10\n",
            "60000/60000 [==============================] - 5s 82us/step - loss: 2.7284e-04 - acc: 1.0000 - val_loss: 0.1011 - val_acc: 0.9858\n",
            "Epoch 9/10\n",
            "60000/60000 [==============================] - 5s 81us/step - loss: 2.7132e-04 - acc: 1.0000 - val_loss: 0.1022 - val_acc: 0.9862\n",
            "Epoch 10/10\n",
            "60000/60000 [==============================] - 5s 82us/step - loss: 2.7046e-04 - acc: 1.0000 - val_loss: 0.1034 - val_acc: 0.9863\n",
            "Test loss: 0.10340754544006399\n",
            "Test accuracy: 0.9863\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "QZZBGctI23BE",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from keras import optimizers\n",
        "nadam=keras.optimizers.Nadam(lr=0.002, beta_1=0.9, beta_2=0.999)\n",
        "\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xoJ4CRqR25cH",
        "colab_type": "code",
        "outputId": "66c6fd7a-79b7-4fbf-9125-51249ef65e85",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 416
        }
      },
      "source": [
        "# Compile model using above optimizer\n",
        "model.compile(optimizer=nadam,\n",
        "              loss='categorical_crossentropy',\n",
        "              metrics=['accuracy'])\n",
        "\n",
        "# Train model\n",
        "model.fit(X_train, y_train,\n",
        "          batch_size=BATCH_SIZE,\n",
        "          epochs=EPOCHS,\n",
        "          verbose=1,\n",
        "          validation_data=(X_test, y_test))\n",
        "\n",
        "score = model.evaluate(X_test, y_test, verbose=0)\n",
        "print('Test loss:', score[0])\n",
        "print('Test accuracy:', score[1])"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Train on 60000 samples, validate on 10000 samples\n",
            "Epoch 1/10\n",
            "60000/60000 [==============================] - 6s 105us/step - loss: 0.0380 - acc: 0.9920 - val_loss: 0.1313 - val_acc: 0.9780\n",
            "Epoch 2/10\n",
            "60000/60000 [==============================] - 6s 97us/step - loss: 0.0173 - acc: 0.9955 - val_loss: 0.1267 - val_acc: 0.9799\n",
            "Epoch 3/10\n",
            "60000/60000 [==============================] - 6s 97us/step - loss: 0.0241 - acc: 0.9936 - val_loss: 0.1225 - val_acc: 0.9797\n",
            "Epoch 4/10\n",
            "60000/60000 [==============================] - 6s 97us/step - loss: 0.0199 - acc: 0.9947 - val_loss: 0.1087 - val_acc: 0.9789\n",
            "Epoch 5/10\n",
            "60000/60000 [==============================] - 6s 97us/step - loss: 0.0188 - acc: 0.9952 - val_loss: 0.1252 - val_acc: 0.9792\n",
            "Epoch 6/10\n",
            "60000/60000 [==============================] - 6s 98us/step - loss: 0.0186 - acc: 0.9950 - val_loss: 0.1840 - val_acc: 0.9696\n",
            "Epoch 7/10\n",
            "60000/60000 [==============================] - 6s 99us/step - loss: 0.0249 - acc: 0.9936 - val_loss: 0.1259 - val_acc: 0.9785\n",
            "Epoch 8/10\n",
            "60000/60000 [==============================] - 6s 98us/step - loss: 0.0151 - acc: 0.9958 - val_loss: 0.1091 - val_acc: 0.9814\n",
            "Epoch 9/10\n",
            "60000/60000 [==============================] - 6s 97us/step - loss: 0.0099 - acc: 0.9971 - val_loss: 0.1104 - val_acc: 0.9809\n",
            "Epoch 10/10\n",
            "60000/60000 [==============================] - 6s 95us/step - loss: 0.0160 - acc: 0.9956 - val_loss: 0.1400 - val_acc: 0.9774\n",
            "Test loss: 0.14000673260290827\n",
            "Test accuracy: 0.9774\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_sziJvs7_K-5",
        "colab_type": "code",
        "outputId": "5c55e549-6aea-43cd-d4b2-7967456fd8b8",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 52
        }
      },
      "source": [
        "score = model.evaluate(X_test, y_test, verbose=0)\n",
        "print('Test loss:', score[0])\n",
        "print('Test accuracy:', score[1])"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Test loss: 0.1497515365727904\n",
            "Test accuracy: 0.9787\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "cfNPmFM4_SFz",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from keras import optimizers\n",
        "adamax=keras.optimizers.Adamax(lr=0.002, beta_1=0.9, beta_2=0.999)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zZPNsE9I_Tmy",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "model.compile(optimizer=adamax,\n",
        "              loss='categorical_crossentropy',\n",
        "              metrics=['accuracy'])\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "UZb7s5mX_VRj",
        "colab_type": "code",
        "outputId": "2dcc843d-b8d4-42bd-bd28-32e84cf06fd4",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 381
        }
      },
      "source": [
        "history=model.fit(X_train, y_train,\n",
        "          batch_size=BATCH_SIZE,\n",
        "          epochs=EPOCHS,\n",
        "          verbose=1,\n",
        "          validation_data=(X_test, y_test))"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Train on 60000 samples, validate on 10000 samples\n",
            "Epoch 1/10\n",
            "60000/60000 [==============================] - 6s 107us/step - loss: 0.0037 - acc: 0.9993 - val_loss: 0.1329 - val_acc: 0.9830\n",
            "Epoch 2/10\n",
            "60000/60000 [==============================] - 6s 93us/step - loss: 5.0997e-04 - acc: 0.9999 - val_loss: 0.1278 - val_acc: 0.9838\n",
            "Epoch 3/10\n",
            "60000/60000 [==============================] - 6s 93us/step - loss: 2.8986e-04 - acc: 1.0000 - val_loss: 0.1268 - val_acc: 0.9836\n",
            "Epoch 4/10\n",
            "60000/60000 [==============================] - 6s 94us/step - loss: 2.8359e-04 - acc: 1.0000 - val_loss: 0.1261 - val_acc: 0.9842\n",
            "Epoch 5/10\n",
            "60000/60000 [==============================] - 6s 94us/step - loss: 2.7948e-04 - acc: 1.0000 - val_loss: 0.1256 - val_acc: 0.9845\n",
            "Epoch 6/10\n",
            "60000/60000 [==============================] - 5s 90us/step - loss: 2.7631e-04 - acc: 1.0000 - val_loss: 0.1253 - val_acc: 0.9847\n",
            "Epoch 7/10\n",
            "60000/60000 [==============================] - 5s 90us/step - loss: 2.7405e-04 - acc: 1.0000 - val_loss: 0.1250 - val_acc: 0.9847\n",
            "Epoch 8/10\n",
            "60000/60000 [==============================] - 5s 91us/step - loss: 2.7235e-04 - acc: 1.0000 - val_loss: 0.1253 - val_acc: 0.9846\n",
            "Epoch 9/10\n",
            "60000/60000 [==============================] - 5s 91us/step - loss: 2.7117e-04 - acc: 1.0000 - val_loss: 0.1252 - val_acc: 0.9850\n",
            "Epoch 10/10\n",
            "60000/60000 [==============================] - 6s 93us/step - loss: 2.7036e-04 - acc: 1.0000 - val_loss: 0.1251 - val_acc: 0.9849\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Nd0cJhjL_d5l",
        "colab_type": "code",
        "outputId": "887cc9a4-fe2c-42ca-f8aa-f47441f56af1",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 52
        }
      },
      "source": [
        "score = model.evaluate(X_test, y_test, verbose=0)\n",
        "print('Test loss:', score[0])\n",
        "print('Test accuracy:', score[1])"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Test loss: 0.12511528191668062\n",
            "Test accuracy: 0.9849\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7LaC0r2-_g55",
        "colab_type": "code",
        "outputId": "dfc39b7e-cb80-4003-9fdb-d54806f13018",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 260
        }
      },
      "source": [
        "model.summary()"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Model: \"sequential_1\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "dense_1 (Dense)              (None, 512)               401920    \n",
            "_________________________________________________________________\n",
            "dense_2 (Dense)              (None, 256)               131328    \n",
            "_________________________________________________________________\n",
            "dense_3 (Dense)              (None, 10)                2570      \n",
            "=================================================================\n",
            "Total params: 535,818\n",
            "Trainable params: 535,818\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "kOisQlN4_ldA",
        "colab_type": "code",
        "outputId": "b35b6d7e-e5b0-41eb-d7f1-94e5b6c0f998",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 573
        }
      },
      "source": [
        "import matplotlib.pyplot as plt\n",
        "plt.plot(history.history['acc'])\n",
        "plt.plot(history.history['val_acc'])\n",
        "plt.title('Model accuracy')\n",
        "plt.ylabel('Accuracy')\n",
        "plt.xlabel('Epoch')\n",
        "plt.legend(['Train', 'Test'], loc='upper left')\n",
        "plt.show()\n",
        "\n",
        "\n",
        "plt.plot(history.history['loss'])\n",
        "plt.plot(history.history['val_loss'])\n",
        "plt.title('Model loss')\n",
        "plt.ylabel('Loss')\n",
        "plt.xlabel('Epoch'  )\n",
        "plt.legend(['Train', 'Test'], loc='upper left')\n",
        "plt.show()"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAZUAAAEWCAYAAACufwpNAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nrkJggg==\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAYgAAAEWCAYAAAB8LwAVAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nZpkcEGZmlskBYWZmmRwQZmaW6f8D7TQF6iuL4KQAAAAASUVORK5CYII=\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0WtGNESe_mHh",
        "colab_type": "code",
        "outputId": "a8a434f6-5e07-40f3-ee32-e5e5928ef9b3",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 491
        }
      },
      "source": [
        "SVG(model_to_dot(model).create(prog='dot', format='svg'))"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<IPython.core.display.SVG object>"
            ],
            "image/svg+xml": "<svg height=\"352pt\" viewBox=\"0.00 0.00 181.00 264.00\" width=\"241pt\" xmlns=\"http://www.w3.org/2000/svg\" xmlns:xlink=\"http://www.w3.org/1999/xlink\">\n<g class=\"graph\" id=\"graph0\" transform=\"scale(1.3333 1.3333) rotate(0) translate(4 260)\">\n<title>G</title>\n<polygon fill=\"#ffffff\" points=\"-4,4 -4,-260 177,-260 177,4 -4,4\" stroke=\"transparent\"/>\n<!-- 140235776688872 -->\n<g class=\"node\" id=\"node1\">\n<title>140235776688872</title>\n<polygon fill=\"none\" points=\"0,-219.5 0,-255.5 173,-255.5 173,-219.5 0,-219.5\" stroke=\"#000000\"/>\n<text fill=\"#000000\" font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"86.5\" y=\"-233.8\">dense_1_input: InputLayer</text>\n</g>\n<!-- 140235776569072 -->\n<g class=\"node\" id=\"node2\">\n<title>140235776569072</title>\n<polygon fill=\"none\" points=\"33,-146.5 33,-182.5 140,-182.5 140,-146.5 33,-146.5\" stroke=\"#000000\"/>\n<text fill=\"#000000\" font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"86.5\" y=\"-160.8\">dense_1: Dense</text>\n</g>\n<!-- 140235776688872&#45;&gt;140235776569072 -->\n<g class=\"edge\" id=\"edge1\">\n<title>140235776688872-&gt;140235776569072</title>\n<path d=\"M86.5,-219.4551C86.5,-211.3828 86.5,-201.6764 86.5,-192.6817\" fill=\"none\" stroke=\"#000000\"/>\n<polygon fill=\"#000000\" points=\"90.0001,-192.5903 86.5,-182.5904 83.0001,-192.5904 90.0001,-192.5903\" stroke=\"#000000\"/>\n</g>\n<!-- 140235776688536 -->\n<g class=\"node\" id=\"node3\">\n<title>140235776688536</title>\n<polygon fill=\"none\" points=\"33,-73.5 33,-109.5 140,-109.5 140,-73.5 33,-73.5\" stroke=\"#000000\"/>\n<text fill=\"#000000\" font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"86.5\" y=\"-87.8\">dense_2: Dense</text>\n</g>\n<!-- 140235776569072&#45;&gt;140235776688536 -->\n<g class=\"edge\" id=\"edge2\">\n<title>140235776569072-&gt;140235776688536</title>\n<path d=\"M86.5,-146.4551C86.5,-138.3828 86.5,-128.6764 86.5,-119.6817\" fill=\"none\" stroke=\"#000000\"/>\n<polygon fill=\"#000000\" points=\"90.0001,-119.5903 86.5,-109.5904 83.0001,-119.5904 90.0001,-119.5903\" stroke=\"#000000\"/>\n</g>\n<!-- 140235776689600 -->\n<g class=\"node\" id=\"node4\">\n<title>140235776689600</title>\n<polygon fill=\"none\" points=\"33,-.5 33,-36.5 140,-36.5 140,-.5 33,-.5\" stroke=\"#000000\"/>\n<text fill=\"#000000\" font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"86.5\" y=\"-14.8\">dense_3: Dense</text>\n</g>\n<!-- 140235776688536&#45;&gt;140235776689600 -->\n<g class=\"edge\" id=\"edge3\">\n<title>140235776688536-&gt;140235776689600</title>\n<path d=\"M86.5,-73.4551C86.5,-65.3828 86.5,-55.6764 86.5,-46.6817\" fill=\"none\" stroke=\"#000000\"/>\n<polygon fill=\"#000000\" points=\"90.0001,-46.5903 86.5,-36.5904 83.0001,-46.5904 90.0001,-46.5903\" stroke=\"#000000\"/>\n</g>\n</g>\n</svg>"
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 46
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "jIXX9z2R_94C",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}